{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/omid-sakaki-ghazvini/Practices/blob/main/Spam_SMS_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "085b3923",
      "metadata": {
        "id": "085b3923"
      },
      "source": [
        "# 1. Install Dependencies and Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e46cc135",
      "metadata": {
        "id": "e46cc135"
      },
      "source": [
        "<div style=\"direction:rtl\">\n",
        "<font color='green' size=\"5px\">\n",
        " کتابخانه های مورد نیاز را نصب میکنیم\n",
        "    </font>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d7f662c",
      "metadata": {
        "id": "6d7f662c"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import itertools\n",
        "from collections import Counter\n",
        "import re\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "from keras.layers import Input, Embedding, Activation, Flatten, Dense\n",
        "from keras.layers import Conv1D, MaxPooling1D, Dropout, LSTM\n",
        "from keras.models import Model\n",
        "from keras import metrics\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from catboost import CatBoostClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd3a50f9",
      "metadata": {
        "id": "fd3a50f9"
      },
      "source": [
        "<div style=\"direction:rtl\">\n",
        "<font color='green' size=\"5px\">\n",
        "    از لینک زیر دیتاست را دانلود کرده و در پوشه هم مسیر همین ژوپیتر نوت بوک قرار دهید یا خط فرمان زیر را اجرا نمایید\n",
        "    </font>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9b504bb",
      "metadata": {
        "id": "f9b504bb"
      },
      "outputs": [],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"mariumfaheem666/spam-sms-classification-using-nlp\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "def1ee54",
      "metadata": {
        "id": "def1ee54"
      },
      "source": [
        "## https://www.kaggle.com/datasets/omidsakaki1370/euro-and-dollar-currency"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b01a837",
      "metadata": {
        "id": "3b01a837"
      },
      "source": [
        "# 2. Load Data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8fb2e15f",
      "metadata": {
        "id": "8fb2e15f"
      },
      "source": [
        "<div style=\"direction:rtl\">\n",
        "<font color='green' size=\"5px\">\n",
        "توسط خط فرمان زیر، دیتا را فراخوانی میکنیم\n",
        "    </font>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0bdded7",
      "metadata": {
        "id": "f0bdded7"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/kaggle/input/spam-sms-classification-using-nlp/Spam_SMS.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "986f48f2",
      "metadata": {
        "id": "986f48f2"
      },
      "source": [
        "# 3.Data preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3881501",
      "metadata": {
        "id": "e3881501"
      },
      "outputs": [],
      "source": [
        "missing_values_count = df.isnull().sum()\n",
        "missing_values_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20080a61",
      "metadata": {
        "id": "20080a61"
      },
      "outputs": [],
      "source": [
        "def clean_str(string):\n",
        "\n",
        "    string = re.sub(r\"[^A-Za-z0-9(),!?\\'\\`]\", \" \", string)\n",
        "    string = re.sub(r\"\\'s\", \" \\'s\", string)\n",
        "    string = re.sub(r\"\\'ve\", \" \\'ve\", string)\n",
        "    string = re.sub(r\"n\\'t\", \" n\\'t\", string)\n",
        "    string = re.sub(r\"\\'re\", \" \\'re\", string)\n",
        "    string = re.sub(r\"\\'d\", \" \\'d\", string)\n",
        "    string = re.sub(r\"\\'ll\", \" \\'ll\", string)\n",
        "    string = re.sub(r\",\", \" , \", string)\n",
        "    string = re.sub(r\"!\", \" ! \", string)\n",
        "    string = re.sub(r\"\\(\", \" \\( \", string)\n",
        "    string = re.sub(r\"\\)\", \" \\) \", string)\n",
        "    string = re.sub(r\"\\?\", \" \\? \", string)\n",
        "    string = re.sub(r\"\\s{2,}\", \" \", string)\n",
        "    return string.strip().lower()\n",
        "\n",
        "df['Message'] = [clean_str(Message) for Message in df['Message']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81be6133",
      "metadata": {
        "id": "81be6133"
      },
      "outputs": [],
      "source": [
        "X = df['Message']\n",
        "Y = df['Class']\n",
        "print('Number of Dataset sentence' , X.shape)\n",
        "print('Number of Dataset labels' , Y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c7aeac4",
      "metadata": {
        "id": "0c7aeac4"
      },
      "outputs": [],
      "source": [
        "cnt = Counter(Y)\n",
        "cnt = dict(cnt)\n",
        "print(cnt)\n",
        "\n",
        "sns.countplot(x='Class', data=df);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a510924",
      "metadata": {
        "id": "3a510924"
      },
      "outputs": [],
      "source": [
        "labels = list(cnt.keys())\n",
        "sizes = list(cnt.values())\n",
        "colors = ['#3fba36', '#66b3ff','#ffcc99','#ff9999', '#d44444']\n",
        "fig1, ax1 = plt.subplots()\n",
        "ax1.pie(sizes, labels=labels, colors=colors,\n",
        "        autopct='%1.1f%%', startangle=90)\n",
        "#draw circle\n",
        "centre_circle = plt.Circle((0,0),0.70,fc='white')\n",
        "fig = plt.gcf()\n",
        "fig.gca().add_artist(centre_circle)\n",
        "ax1.axis('equal')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "518b116e",
      "metadata": {
        "id": "518b116e"
      },
      "outputs": [],
      "source": [
        "max_fatures = 2000\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_fatures, split=' ')\n",
        "tokenizer.fit_on_texts(df['Message'].values)\n",
        "\n",
        "X = tokenizer.texts_to_sequences(df['Message'].values)\n",
        "\n",
        "X = pad_sequences(X,maxlen=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab480a3a",
      "metadata": {
        "id": "ab480a3a"
      },
      "outputs": [],
      "source": [
        "le = LabelEncoder()\n",
        "Y = le.fit_transform(df['Class'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "231e8b61",
      "metadata": {
        "id": "231e8b61"
      },
      "outputs": [],
      "source": [
        "def plot_confusion_matrix(cm,\n",
        "                          target_names,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=None,\n",
        "                          normalize=True):\n",
        "\n",
        "\n",
        "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
        "    misclass = 1 - accuracy\n",
        "\n",
        "    if cmap is None:\n",
        "        cmap = plt.get_cmap('Blues')\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "\n",
        "    if target_names is not None:\n",
        "        tick_marks = np.arange(len(target_names))\n",
        "        plt.xticks(tick_marks, target_names, rotation=45)\n",
        "        plt.yticks(tick_marks, target_names)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        if normalize:\n",
        "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "        else:\n",
        "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97b55acc",
      "metadata": {
        "id": "97b55acc"
      },
      "outputs": [],
      "source": [
        "results = {}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0bc6f22c",
      "metadata": {
        "id": "0bc6f22c"
      },
      "source": [
        "# 4. Split & Scale Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "458dc72a",
      "metadata": {
        "id": "458dc72a"
      },
      "outputs": [],
      "source": [
        "X_train,X_test,y_train,y_test=train_test_split(X,Y, test_size=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a9874622",
      "metadata": {
        "id": "a9874622"
      },
      "source": [
        "# 5.ML models"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c8d0ee77",
      "metadata": {
        "id": "c8d0ee77"
      },
      "source": [
        "## 5.1.XGB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08a5cda1",
      "metadata": {
        "id": "08a5cda1"
      },
      "outputs": [],
      "source": [
        "XGB = XGBClassifier()\n",
        "XGB.fit(X_train,y_train)\n",
        "prediction=XGB.predict(X_test)\n",
        "\n",
        "results['XGB'] = {\n",
        "        'Accuracy': accuracy_score(y_test, prediction),\n",
        "    }\n",
        "\n",
        "cm = confusion_matrix(prediction,y_test)\n",
        "print(cm)\n",
        "plot_confusion_matrix(cm,\n",
        "                          target_names=['ham', 'spam'],\n",
        "                          title='XGB Classifier',\n",
        "                          cmap=None,\n",
        "                          normalize=True)\n",
        "sk_report = classification_report(\n",
        "    digits=2,\n",
        "    y_true=prediction,\n",
        "    y_pred=y_test)\n",
        "print(sk_report)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1a2d4fe",
      "metadata": {
        "id": "a1a2d4fe"
      },
      "source": [
        "## 5.2.LGBM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1afb2143",
      "metadata": {
        "id": "1afb2143"
      },
      "outputs": [],
      "source": [
        "LGBM = LGBMClassifier()\n",
        "LGBM.fit(X_train,y_train)\n",
        "prediction=LGBM.predict(X_test)\n",
        "\n",
        "results['LGBM'] = {\n",
        "        'Accuracy': accuracy_score(y_test, prediction),\n",
        "    }\n",
        "\n",
        "cm = confusion_matrix(prediction,y_test)\n",
        "print(cm)\n",
        "plot_confusion_matrix(cm,\n",
        "                          target_names=['ham', 'spam'],\n",
        "                          title='LGBM Classifier',\n",
        "                          cmap=None,\n",
        "                          normalize=True)\n",
        "sk_report = classification_report(\n",
        "    digits=2,\n",
        "    y_true=prediction,\n",
        "    y_pred=y_test)\n",
        "print(sk_report)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22f3a7e6",
      "metadata": {
        "id": "22f3a7e6"
      },
      "source": [
        "# 6.Deep Model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d284a8fb",
      "metadata": {
        "id": "d284a8fb"
      },
      "source": [
        "## 6.1. Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd8ab7bd",
      "metadata": {
        "id": "dd8ab7bd"
      },
      "outputs": [],
      "source": [
        "def char_cnn_model(text, labels, num_epochs):\n",
        "\n",
        "    tk = Tokenizer(lower=True, char_level=True, oov_token='UNK')\n",
        "    tk.fit_on_texts(text)\n",
        "    sequences = tk.texts_to_sequences(text)\n",
        "\n",
        "    data = pad_sequences(sequences, maxlen=input_size)\n",
        "    labels = to_categorical(labels)\n",
        "\n",
        "    vocab_size = len(tk.word_index)\n",
        "\n",
        "    x_train, x_test, y_train, y_test = train_test_split(data, labels, test_size = 0.1, random_state = 42)\n",
        "\n",
        "    #creating embedding matrix\n",
        "    embedding_weights = []\n",
        "    embedding_weights.append(np.zeros(vocab_size))\n",
        "\n",
        "    for char, i in tk.word_index.items():\n",
        "        onehot = np.zeros(vocab_size)\n",
        "        onehot[i - 1] = 1\n",
        "        embedding_weights.append(onehot)\n",
        "\n",
        "    embedding_weights = np.array(embedding_weights)\n",
        "\n",
        "    embedding_layer = Embedding(vocab_size + 1, vocab_size, input_length=input_size, weights=[embedding_weights])\n",
        "\n",
        "    #Model architecture\n",
        "    inputs = Input(shape=(input_size,), name='input', dtype='int64')\n",
        "    x = embedding_layer(inputs)\n",
        "\n",
        "    for filter_num, filter_size, pooling_size in conv_layers:\n",
        "        x = Conv1D(filter_num, filter_size)(x)\n",
        "        x = Dropout(dropout_p)(x)\n",
        "        x = Activation('relu')(x)\n",
        "        if pooling_size != -1:\n",
        "            x = MaxPooling1D(pool_size=pooling_size)(x)\n",
        "    x = Flatten()(x)\n",
        "\n",
        "    for dense_size in fully_connected_layers:\n",
        "        x = Dense(dense_size, activation='relu')(x)\n",
        "        x = Dropout(dropout_p)(x)\n",
        "\n",
        "    predictions = Dense(num_of_classes, activation='softmax')(x)\n",
        "\n",
        "    # Build model\n",
        "    model = Model(inputs=inputs, outputs=predictions)\n",
        "    model.compile(optimizer=optimizer, loss=loss_type, metrics=['accuracy'])\n",
        "    hist=model.fit(x_train, y_train, epochs=num_epochs,validation_data=(x_test,y_test), batch_size=100)\n",
        "\n",
        "    #loss, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
        "\n",
        "    return x_train, x_test, y_train, y_test,hist,model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84fc2b84",
      "metadata": {
        "id": "84fc2b84"
      },
      "source": [
        "## 6.2.Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11d38f40",
      "metadata": {
        "id": "11d38f40"
      },
      "outputs": [],
      "source": [
        "le = LabelEncoder()\n",
        "labels = le.fit_transform(df['Class'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64ae0ede",
      "metadata": {
        "id": "64ae0ede"
      },
      "outputs": [],
      "source": [
        "input_size = 100\n",
        "conv_layers = [[256, 3, 3]]\n",
        "\n",
        "fully_connected_layers = [128]\n",
        "num_of_classes = 2\n",
        "dropout_p = 0.5\n",
        "optimizer = 'adam'\n",
        "loss_type = 'categorical_crossentropy'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b55b657",
      "metadata": {
        "id": "3b55b657"
      },
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test,hist,CNN_model = char_cnn_model(df['Message'], labels, num_epochs=25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b30aaba",
      "metadata": {
        "id": "2b30aaba"
      },
      "outputs": [],
      "source": [
        "prediction=CNN_model.predict(x_test)\n",
        "\n",
        "results['CNN'] = {\n",
        "        'Accuracy': accuracy_score(np.argmax(y_test,axis=-1), np.argmax(prediction,axis=-1)),\n",
        "    }\n",
        "\n",
        "cm = confusion_matrix(np.argmax(prediction,axis=-1),np.argmax(y_test,axis=-1))\n",
        "print(cm)\n",
        "\n",
        "plot_confusion_matrix(cm,\n",
        "                          target_names=['ham', 'spam'],\n",
        "                          title='CNN',\n",
        "                          cmap=None,\n",
        "                          normalize=True)\n",
        "\n",
        "sk_report = classification_report(np.argmax(prediction,axis=-1),np.argmax(y_test,axis=-1))\n",
        "print(sk_report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f415a656",
      "metadata": {
        "id": "f415a656"
      },
      "outputs": [],
      "source": [
        "cnn=hist\n",
        "plt.figure(0)\n",
        "plt.plot(cnn.history['accuracy'],'r')\n",
        "plt.plot(cnn.history['val_accuracy'],'g')\n",
        "plt.xticks(np.arange(0, 11, 2.0))\n",
        "plt.rcParams['figure.figsize'] = (8, 6)\n",
        "plt.xlabel(\"Num of Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Training Accuracy vs Validation Accuracy\")\n",
        "plt.legend(['train','validation'])\n",
        "\n",
        "plt.figure(1)\n",
        "plt.plot(cnn.history['loss'],'r')\n",
        "plt.plot(cnn.history['val_loss'],'g')\n",
        "plt.xticks(np.arange(0, 11, 2.0))\n",
        "plt.rcParams['figure.figsize'] = (8, 6)\n",
        "plt.xlabel(\"Num of Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Training Loss vs Validation Loss\")\n",
        "plt.legend(['train','validation'])\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4bf9713b",
      "metadata": {
        "id": "4bf9713b"
      },
      "source": [
        "# 7.Result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da36efc1",
      "metadata": {
        "id": "da36efc1"
      },
      "outputs": [],
      "source": [
        "results_df = pd.DataFrame(results).T\n",
        "results_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d539d7f4",
      "metadata": {
        "id": "d539d7f4"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "sns.lineplot(results_df);"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}